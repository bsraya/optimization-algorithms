# Optimization Algorithms

1. Batch Gradient Descent :white_check_mark:
2. Mini-Batch Gradient Descent :white_check_mark:
3. Stochastic Gradient Descent :white_check_mark:
4. SGD with Momentum (on-going)
